# VnStock News - HÆ°á»›ng Dáº«n Chi Tiáº¿t

**vnstock_news** lÃ  thÆ° viá»‡n Python cung cáº¥p kháº£ nÄƒng thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch tin tá»©c tá»« cÃ¡c trang bÃ¡o Viá»‡t Nam. ThÆ° viá»‡n cung cáº¥p cáº¥u hÃ¬nh sáºµn cho **12+ trang bÃ¡o** phá»• biáº¿n nhÆ°ng cÃ³ thá»ƒ tÃ¹y biáº¿n Ä‘á»ƒ lÃ m viá»‡c vá»›i **báº¥t ká»³ website/bÃ¡o nÃ o** cÃ³ nguá»“n RSS/sitemap Ä‘á»ƒ cung cáº¥p danh sÃ¡ch cho thuáº­t toÃ¡n Ä‘á»c bÃ i viáº¿t chi tiáº¿t.

## ğŸ“š Danh SÃ¡ch TÃ i Liá»‡u

HÆ°á»›ng dáº«n Ä‘Æ°á»£c chia thÃ nh cÃ¡c pháº§n:

### 1. **[01-overview.md](./01-overview.md)** - Giá»›i Thiá»‡u & Báº¯t Äáº§u
- â“ vnstock_news lÃ  gÃ¬?
- ğŸ“° Nhá»¯ng bÃ¡o nÃ o Ä‘Æ°á»£c há»— trá»£
- ğŸ”„ PhÆ°Æ¡ng thá»©c thu tháº­p dá»¯ liá»‡u (RSS vs Sitemap)
- ğŸ“Š Cáº¥u trÃºc dá»¯ liá»‡u output
- âš¡ Quickstart 3 vÃ­ dá»¥

**Cho ai?** NgÆ°á»i má»›i báº¯t Ä‘áº§u, muá»‘n hiá»ƒu cÆ¡ báº£n

---

### 2. **[02-crawlers.md](./02-crawlers.md)** - Chi Tiáº¿t CÃ¡c Crawler
- ğŸ“– 7 loáº¡i crawler khÃ¡c nhau
- ğŸ”§ CÃ¡c method vÃ  parameter cá»§a tá»«ng loáº¡i
- ğŸ’» VÃ­ dá»¥ code chi tiáº¿t
- ğŸ“Š Báº£ng so sÃ¡nh tá»‘c Ä‘á»™/tÃ­nh nÄƒng
- âš ï¸ Xá»­ lÃ½ lá»—i

**Cho ai?** Developer muá»‘n dÃ¹ng API chi tiáº¿t

---

### 3. **[03-sitemap-rss-guide.md](./03-sitemap-rss-guide.md)** - TÃ¬m & Thiáº¿t Láº­p Sitemap/RSS
- ğŸ” CÃ¡ch tÃ¬m sitemap cá»§a bÃ¡o
- ğŸ“¡ CÃ¡ch tÃ¬m RSS feed
- ğŸ“‹ Danh sÃ¡ch 12+ bÃ¡o vá»›i sitemap/RSS
- ğŸ¯ Sitemap Ä‘á»™ng (thÃ¡ng/nÄƒm)
- â• ThÃªm bÃ¡o má»›i
- âš–ï¸ LÆ°u Ã½ phÃ¡p lÃ½ (robots.txt, rate limiting, copyright)

**Cho ai?** Muá»‘n tÃ¬m sitemap/RSS, thÃªm bÃ¡o má»›i

---

### 4. **[04-trending-analysis.md](./04-trending-analysis.md)** - PhÃ¢n TÃ­ch Xu HÆ°á»›ng
- ğŸ”¥ TrendingAnalyzer - cÃ´ng cá»¥ phÃ¢n tÃ­ch keyword
- ğŸ” Extract keywords phá»• biáº¿n
- ğŸ“ˆ PhÃ¢n tÃ­ch trending theo thá»i gian
- ğŸ“Š So sÃ¡nh giá»¯a cÃ¡c bÃ¡o
- ğŸ“‰ Visualization & export

**Cho ai?** PhÃ¢n tÃ­ch dá»¯ liá»‡u, journalist, marketer

---

### 5. **[05-best-practices.md](./05-best-practices.md)** - Best Practices & Tips
- ğŸ¯ Chiáº¿n lÆ°á»£c thu tháº­p dá»¯ liá»‡u
- âš¡ Rate limiting & trÃ¡nh block IP
- ğŸ’¾ Caching & performance
- ğŸ›¡ï¸ Error handling & resume
- ğŸ§¹ Deduplication & cleaning
- ğŸ• Timezone handling
- ğŸš€ Production deployment

**Cho ai?** Production use, muá»‘n optimize performance

---

## ğŸš€ Quickstart - Báº¯t Äáº§u Nhanh

### VÃ­ Dá»¥ 1: Láº¥y 20 BÃ i Má»›i Tá»« VnExpress (30 giÃ¢y)
```python
from vnstock_news import Crawler

crawler = Crawler(site_name="vnexpress")
articles = crawler.get_articles_from_feed(limit_per_feed=20)

print(f"âœ… Láº¥y {len(articles)} bÃ i")
print(articles[['title', 'publish_time']].head())
```

### VÃ­ Dá»¥ 2: Láº¥y 100 BÃ i Lá»‹ch Sá»­ Tá»« CafeF (1 phÃºt)
```python
from vnstock_news import BatchCrawler

crawler = BatchCrawler(site_name="cafef", request_delay=1.0)
articles = crawler.fetch_articles(limit=100)

print(f"âœ… Láº¥y {len(articles)} bÃ i tá»« {articles['publish_time'].min()}")
articles.to_csv("cafef_articles.csv", index=False)
```

### VÃ­ Dá»¥ 3: TÃ¬m Trending Keywords (1 phÃºt)
```python
from vnstock_news import Crawler, TrendingAnalyzer

crawler = Crawler(site_name="cafef")
articles = crawler.get_articles_from_feed(limit_per_feed=50)

analyzer = TrendingAnalyzer()
keywords = analyzer.extract_keywords(articles['title'].tolist(), top_n=10)

for keyword, count in keywords.items():
    print(f"{keyword}: {count}")
```

---

## ğŸ“Š CÃ¡c BÃ¡o ÄÆ°á»£c Há»— Trá»£ (12+ bÃ¡o)

| # | BÃ¡o | Domain | RSS | Sitemap | Ghi ChÃº |
|---|-----|--------|-----|---------|---------|
| 1 | **VnExpress** | vnexpress.net | âœ… | âœ… | RSS cáº­p nháº­t nhanh |
| 2 | **Tuá»•i Tráº»** | tuoitre.vn | âœ… | âœ… | Sitemap thÃ¡ng/nÄƒm |
| 3 | **CafeF** | cafef.vn | âœ… | âœ… | Cáº£ hai |
| 4 | **CafeBiz** | cafebiz.vn | âœ… | âœ… | Cáº£ hai |
| 5 | **VietStock** | vietstock.vn | âœ… | âœ… | Cáº£ hai |
| 6 | **VnEconomy** | vneconomy.vn | âœ… | âœ… | Sitemap XML |
| 7 | **BÃ¡o Äáº§u TÆ°** | baodautu.vn | âœ… | âœ… | Sitemap XML |
| 8 | **PLO** | plo.vn | âœ… | âœ… | Sitemap dynamic (thÃ¡ng/nÄƒm) |
| 9 | **BÃ¡o Má»›i** | baomoi.com | âœ… | âœ… | Sitemap XML |
| 10 | **Tháº¿ Giá»›i TÃ i ChÃ­nh** | thesaigontimes.vn | âœ… | âœ… | Incremental sitemap |
| 11 | **Nhá»‹p Cáº§u Äáº§u TÆ°** | nhipcaudautu.vn | âœ… | âœ… | Sitemap XML |
| 12 | **CÃ´ng ThÆ°Æ¡ng** | congthuong.vn | âœ… | âœ… | Sitemap XML |

**Táº¥t cáº£ cÃ¡c bÃ¡o Ä‘á»u há»— trá»£ cáº£ RSS vÃ  Sitemap** vÃ¬ Ä‘Ã¢y lÃ  tiÃªu chuáº©n web. vnstock_news cung cáº¥p cáº¥u hÃ¬nh sáºµn cho 12+ bÃ¡o phá»• biáº¿n nhÆ°ng cÃ³ thá»ƒ tÃ¹y biáº¿n Ä‘á»ƒ lÃ m viá»‡c vá»›i báº¥t ká»³ website/bÃ¡o nÃ o cÃ³ nguá»“n RSS/sitemap.

**Muá»‘n thÃªm bÃ¡o má»›i?** â†’ Xem [03-sitemap-rss-guide.md](./03-sitemap-rss-guide.md#5-thÃªm-bÃ¡o-má»›i---custom-configuration)

---

## ğŸ” PhÆ°Æ¡ng Thá»©c Thu Tháº­p Dá»¯ Liá»‡u

### RSS Feed - Tin Má»›i Nháº¥t
- âœ… **Tá»‘c Ä‘á»™**: Nhanh (< 10 giÃ¢y)
- âœ… **Cáº­p nháº­t**: ThÆ°á»ng xuyÃªn (hÃ ng giá»)
- âœ… **Dá»¯ liá»‡u**: BÃ i má»›i nháº¥t tá»« bÃ¡o
- âŒ **Lá»‹ch sá»­**: Chá»‰ 1-2 tuáº§n gáº§n Ä‘Ã¢y

**DÃ¹ng cho:** Monitoring tin tÆ°Æ¡i, cáº­p nháº­t hÃ ng ngÃ y

**Code:**
```python
crawler = Crawler(site_name="vnexpress")
articles = crawler.get_articles_from_feed(limit_per_feed=20)
```

---

### Sitemap - Lá»‹ch Sá»­ LÃ¢u DÃ i
- âœ… **Tá»‘c Ä‘á»™**: Cháº­m hÆ¡n (10-60 phÃºt)
- âœ… **Dá»¯ liá»‡u**: Lá»‹ch sá»­ 1-2 nÄƒm
- âœ… **LÆ°á»£ng**: CÃ³ thá»ƒ láº¥y hÃ ng ngÃ n bÃ i
- âŒ **Thá»i gian**: Cáº§n chá» lÃ¢u hÆ¡n

**DÃ¹ng cho:** XÃ¢y dá»±ng database lá»‹ch sá»­, phÃ¢n tÃ­ch

**Code:**
```python
crawler = Crawler(site_name="cafef")
articles = crawler.get_articles_from_sitemap(limit=500)
```

---

### Batch Crawler - Láº¥y HÃ ng Loáº¡t (Äá»“ng Bá»™)
- âœ… **ÄÆ¡n giáº£n**: DÃ¹ng dá»… nháº¥t
- âœ… **Resume**: CÃ³ thá»ƒ tiáº¿p tá»¥c náº¿u bá»‹ lá»—i
- âŒ **Tá»‘c Ä‘á»™**: Láº¥y tá»«ng bÃ i má»™t

**DÃ¹ng cho:** XÃ¢y dá»±ng database, ngÆ°á»i má»›i

**Code:**
```python
crawler = BatchCrawler(site_name="cafef")
articles = crawler.fetch_articles(limit=500)
```

---

### AsyncBatchCrawler - Láº¥y HÃ ng Loáº¡t (Báº¥t Äá»“ng Bá»™)
- âœ… **Tá»‘c Ä‘á»™**: Nhanh gáº¥p 5-10 láº§n
- âœ… **Concurrent**: Láº¥y nhiá»u bÃ i cÃ¹ng lÃºc
- âŒ **Phá»©c táº¡p**: Code async/await

**DÃ¹ng cho:** Production, cáº§n tá»‘c Ä‘á»™ cao

**Code:**
```python
import asyncio
from vnstock_news import AsyncBatchCrawler

async def fetch():
    crawler = AsyncBatchCrawler(site_name="cafef")
    return await crawler.fetch_articles_async(
        site_name="cafef", max_articles=1000
    )

articles = asyncio.run(fetch())
```

---

### EnhancedNewsCrawler - Äáº§y Äá»§ TÃ­nh NÄƒng
- âœ… **Caching**: LÆ°u cache trÃ¡nh láº¥y láº¡i
- âœ… **Cleaning**: Tá»± Ä‘á»™ng lÃ m sáº¡ch ná»™i dung
- âœ… **Validation**: Kiá»ƒm tra dá»¯ liá»‡u
- âœ… **Retry**: Retry tá»± Ä‘á»™ng náº¿u lá»—i

**DÃ¹ng cho:** Production, cáº§n Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng

**Code:**
```python
from vnstock_news import EnhancedNewsCrawler

async def fetch():
    crawler = EnhancedNewsCrawler(cache_enabled=True)
    return await crawler.fetch_articles_async(
        sources=["https://cafef.vn/latest-news-sitemap.xml"],
        site_name="cafef",
        max_articles=100,
        clean_content=True
    )

articles = asyncio.run(fetch())
```

---

## ğŸ“Š Output Data Structure

Táº¥t cáº£ phÆ°Æ¡ng thá»©c Ä‘á»u tráº£ vá» **pandas DataFrame** vá»›i cÃ¡c cá»™t:

| Cá»™t | Kiá»ƒu | VÃ­ Dá»¥ |
|-----|------|-------|
| `url` | string | `https://cafef.vn/article/...` |
| `title` | string | `Chá»©ng khoÃ¡n tÄƒng 1%` |
| `short_description` | string | `Thá»‹ trÆ°á»ng hÃ´m nay tÄƒng...` |
| `content` | string | `Ná»™i dung bÃ i viáº¿t Ä‘áº§y Ä‘á»§...` |
| `publish_time` | datetime | `2025-01-15 10:30:00` |
| `author` | string | `Nguyá»…n VÄƒn A` |
| `category` | string | `TÃ i ChÃ­nh` |
| `source` | string | `cafef` |

**VÃ­ dá»¥:**
```python
articles.head()
#                             url                   title publish_time
# 0  https://cafef.vn/...  Thá»‹ trÆ°á»ng chá»©ng...  2025-01-15
# 1  https://cafef.vn/...  NhÃ  Ä‘áº§u tÆ° lo...  2025-01-14
```

---

## ğŸ’¡ CÃ¡c TrÆ°á»ng Há»£p Sá»­ Dá»¥ng

### ğŸ“ˆ NhÃ  PhÃ¢n TÃ­ch TÃ i ChÃ­nh
```python
# Láº¥y tin tá»« 3 thÃ¡ng, phÃ¢n tÃ­ch trending keyword
from vnstock_news import AsyncBatchCrawler, TrendingAnalyzer

async def analyze():
    crawler = AsyncBatchCrawler(site_name="cafef")
    articles = await crawler.fetch_articles_async(
        site_name="cafef", max_articles=5000
    )
    
    analyzer = TrendingAnalyzer()
    keywords = analyzer.extract_keywords(articles['content'].tolist(), top_n=50)
    
    return keywords

keywords = asyncio.run(analyze())
```

---

### ğŸ“° Journalist / Content Creator
```python
# Monitoring tin má»›i nháº¥t, kiá»ƒm tra trending hÃ ng ngÃ y
from vnstock_news import Crawler
import schedule
import time

def check_trending():
    crawler = Crawler(site_name="tuoitre")
    articles = crawler.get_articles_from_feed(limit_per_feed=30)
    
    print(f"ğŸ“° Tin má»›i: {len(articles)} bÃ i")
    print(articles[['title', 'publish_time']].head(10))

# Cháº¡y má»—i 1 giá»
schedule.every(1).hours.do(check_trending)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

### ğŸ¤– Data Scientist / ML Engineer
```python
# XÃ¢y dá»±ng dataset tin tá»©c Ä‘á»ƒ training model
from vnstock_news import AsyncBatchCrawler
import pandas as pd

async def build_dataset():
    all_articles = []
    
    sites = ["cafef", "tuoitre", "vietstock", "vnexpress"]
    
    for site in sites:
        crawler = AsyncBatchCrawler(site_name=site)
        articles = await crawler.fetch_articles_async(
            site_name=site, max_articles=2000
        )
        articles['source'] = site
        all_articles.append(articles)
    
    dataset = pd.concat(all_articles)
    dataset.to_csv("news_dataset_10k.csv", index=False)
    
    return dataset

dataset = asyncio.run(build_dataset())
```

---

### ğŸ” Market Researcher
```python
# Theo dÃµi topic cá»¥ thá»ƒ, phÃ¢n tÃ­ch táº§n suáº¥t mention
from vnstock_news import Crawler, TrendingAnalyzer

crawler = Crawler(site_name="cafef")
articles = crawler.get_articles_from_sitemap(limit=1000)

# Lá»c bÃ i Ä‘á» cáº­p Ä‘áº¿n "FED" hoáº·c "lÃ£i suáº¥t"
filtered = articles[
    (articles['title'].str.contains('FED|lÃ£i suáº¥t', case=False, na=False))
]

print(f"Found {len(filtered)} articles mentioning FED or interest rates")
print(f"Date range: {filtered['publish_time'].min()} to {filtered['publish_time'].max()}")
```

---

## ğŸ›¡ï¸ LÆ°u Ã Quan Trá»ng - Legal & Ethical

âš ï¸ **NGÆ¯á»œI DÃ™NG Tá»° CHá»ŠU TRÃCH NHIá»†M** vá»›i cÃ¡c váº¥n Ä‘á» sau:

### 1ï¸âƒ£ Báº£n Quyá»n
- Ná»™i dung bÃ¡o cÃ³ **báº£n quyá»n** Â©
- **Chá»‰ dÃ¹ng Ä‘á»ƒ há»c táº­p, nghiÃªn cá»©u cÃ¡ nhÃ¢n**
- **KhÃ´ng tÃ¡i xuáº¥t báº£n, khÃ´ng bÃ¡n, khÃ´ng thÆ°Æ¡ng máº¡i hÃ³a**

### 2ï¸âƒ£ Terms of Service
- Äá»c ká»¹ ToS cá»§a trang bÃ¡o trÆ°á»›c crawling
- Má»™t sá»‘ bÃ¡o cáº¥m crawling trong ToS
- TuÃ¢n thá»§ cÃ¡c quy Ä‘á»‹nh cá»§a bÃ¡o

### 3ï¸âƒ£ Robots.txt & Rate Limiting
- Kiá»ƒm tra `/robots.txt` trÆ°á»›c crawl
- TuÃ¢n thá»§ `Crawl-delay` (náº¿u cÃ³)
- KhÃ´ng crawl cÃ¡c path bá»‹ `Disallow`
- ThÃªm delay 1-2 giÃ¢y giá»¯a má»—i request

### 4ï¸âƒ£ Block IP & Rate Limit
- Náº¿u bá»‹ 429 (Too Many Requests) â†’ Dá»«ng láº¡i 1-2 giá»
- Náº¿u bá»‹ 403 (Forbidden) â†’ IP bá»‹ block, dÃ¹ng VPN
- Giáº£m concurrency / tÄƒng request_delay

### 5ï¸âƒ£ Privacy & GDPR
- KhÃ´ng crawl thÃ´ng tin cÃ¡ nhÃ¢n (email, sá»‘ Ä‘iá»‡n thoáº¡i)
- TuÃ¢n thá»§ luáº­t GDPR vÃ  privacy Ä‘á»‹a phÆ°Æ¡ng

**Xem chi tiáº¿t:** [03-sitemap-rss-guide.md - Section 8](./03-sitemap-rss-guide.md#8-lÆ°u-Ã½-quan-trá»ng---legal--ethical)

---

## â“ FAQ

### Q: BÃ¡o má»›i khÃ´ng cÃ³ trong danh sÃ¡ch, thÃªm nhÆ° tháº¿ nÃ o?
**A:** Xem [03-sitemap-rss-guide.md - Section 5](./03-sitemap-rss-guide.md#5-thÃªm-bÃ¡o-má»›i---custom-configuration)

---

### Q: Bá»‹ block IP, pháº£i lÃ m gÃ¬?
**A:** 
1. Dá»«ng crawl ngay láº­p tá»©c
2. Äá»£i 1-2 giá»
3. TÄƒng `request_delay` lÃªn 3-5 giÃ¢y
4. Giáº£m `max_concurrency` xuá»‘ng 2-3
5. DÃ¹ng VPN (náº¿u cáº§n)
6. Xem [05-best-practices.md - Section 2](./05-best-practices.md#2-rate-limiting--trÃ¡nh-block-ip)

---

### Q: Láº¥y toÃ n bá»™ lá»‹ch sá»­ (1-2 nÄƒm) tá»« má»™t bÃ¡o máº¥t bao lÃ¢u?
**A:** 
- **AsyncBatchCrawler** (nhanh): 10-30 phÃºt
- **BatchCrawler** (cháº­m): 1-2 giá»
- Phá»¥ thuá»™c vÃ o sá»‘ lÆ°á»£ng bÃ i + request_delay

---

### Q: Cache hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?
**A:**
- Cache lÆ°u URL Ä‘Ã£ fetch
- Náº¿u fetch láº¡i URL trong TTL (time-to-live), láº¥y tá»« cache
- TTL máº·c Ä‘á»‹nh: 2 giá»
- Tiáº¿t kiá»‡m bandwidth 30-50%

---

### Q: Dá»¯ liá»‡u output cÃ³ HTML hay Ä‘Ã£ lÃ m sáº¡ch?
**A:** 
- Máº·c Ä‘á»‹nh: CÃ³ HTML
- DÃ¹ng `EnhancedNewsCrawler` vá»›i `clean_content=True` Ä‘á»ƒ xÃ³a HTML
- Hoáº·c tá»± lÃ m sáº¡ch xem [05-best-practices.md - Section 5](./05-best-practices.md#5-deduplication--data-cleaning)

---

### Q: CÃ³ há»— trá»£ tiáº¿ng Anh khÃ´ng?
**A:** vnstock_news tá»‘i Æ°u cho **tiáº¿ng Viá»‡t**. TrendingAnalyzer cÃ³ `language='english'` nhÆ°ng chá»‰ lÃ  basic.

---

## ğŸ“ Support & Contribution

- ğŸ› **Bug Report**: https://github.com/vnstock-lab/vnstock/issues
- ğŸ’¡ **Feature Request**: https://github.com/vnstock-lab/vnstock/discussions
- ğŸ“§ **Email**: support@vnstock.com

---

## ğŸ“š TÃ i Liá»‡u LiÃªn Quan

- **Vnstock Official Docs**: https://vnstocks.com/
- **GitHub Repository**: https://github.com/vnstock-lab/vnstock
- **Sitemap Protocol**: https://www.sitemaps.org/
- **RSS Standard**: https://www.rssboard.org/
- **Robots.txt Guide**: https://www.robotstxt.org/

---

## ğŸ“‹ Roadmap

- [ ] Support RSS 2.0 full features
- [ ] Add more Vietnamese news sites (20+)
- [ ] Sentiment analysis cho tiáº¿ng Viá»‡t
- [ ] NER (Named Entity Recognition) Ä‘á»ƒ extract entities
- [ ] Database backend support (PostgreSQL, MongoDB)
- [ ] Web UI dashboard
- [ ] API server

---

## ğŸ“„ License

vnstock_news lÃ  má»™t pháº§n cá»§a **vnstock** - cÃ´ng cá»¥ phÃ¢n tÃ­ch thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam.

**License**: MIT

---

## ğŸ™ Cáº£m Æ n

Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng vnstock_news. Vui lÃ²ng tuÃ¢n thá»§ cÃ¡c quy táº¯c phÃ¡p lÃ½ vÃ  Ä‘áº¡o Ä‘á»©c trong quÃ¡ trÃ¬nh sá»­ dá»¥ng.

Happy analyzing! ğŸ“Š
